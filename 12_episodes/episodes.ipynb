{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e0907f-f866-4e89-b41f-84c036af7483",
   "metadata": {},
   "source": [
    "# Terminal states and episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65297414-cb26-4820-ae9a-7c86ea01775b",
   "metadata": {},
   "source": [
    "<img src=\"slides/images/terminal/2.png\" width=\"750\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49ec423-bfdf-41fb-a073-ae0abafd9a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68c391e-e832-4899-b3b7-b8615d94c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01401658, -0.22265474, -0.03178046,  0.27844635]), 1.0, False, {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503141ec-0d34-475f-9de5-6e78356a4f5f",
   "metadata": {},
   "source": [
    "## The third element of the return value of `env.step(action)` indicates if we have reached a terminal state\n",
    "\n",
    "- called `done` (`type: bool`)\n",
    "- `True` indicates terminal state reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0cb62d2-d4ed-4fee-8e0d-151a6583001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "obs, reward, done, _ = env.step(0)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a6d48-6018-4133-8c3e-9c7d6f60c8b7",
   "metadata": {},
   "source": [
    "## Demo of terminal states in `CartPole-v1`\n",
    "\n",
    "<img src=\"slides/images/cp_terminal/6.png\" width=\"750\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87876d0f-9022-4849-8d69-ca0efd7a6f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pole angle at step start: 2.5225715240513926 Pole angle at step end: 2.5628541577896797 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 2.5628541577896797 Pole angle at step end: 2.9540647813957777 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 2.9540647813957777 Pole angle at step end: 3.6964366026209015 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 3.6964366026209015 Pole angle at step end: 4.792280374650069 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 4.792280374650069 Pole angle at step end: 6.245918098510648 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 6.245918098510648 Pole angle at step end: 8.063567923896485 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 8.063567923896485 Pole angle at step end: 10.253173624787452 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 10.253173624787452 Pole angle at step end: 12.824169097187262 Reward in step: 1.0, done: True\n",
      "Pole angle at step start: 12.824169097187262 Pole angle at step end: 15.787166516918928 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 15.787166516918928 Pole angle at step end: 19.153556814917724 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 19.153556814917724 Pole angle at step end: 22.935013924065565 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 22.935013924065565 Pole angle at step end: 27.14290088502719 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 27.14290088502719 Pole angle at step end: 31.78758720022623 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 31.78758720022623 Pole angle at step end: 36.87770278187503 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 36.87770278187503 Pole angle at step end: 42.41937274589036 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 42.41937274589036 Pole angle at step end: 48.415494960622226 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 48.415494960622226 Pole angle at step end: 54.865131822824914 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 54.865131822824914 Pole angle at step end: 61.76308096594259 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 61.76308096594259 Pole angle at step end: 69.09965995043892 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 69.09965995043892 Pole angle at step end: 76.860686760074 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 76.860686760074 Pole angle at step end: 85.02756955679854 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 85.02756955679854 Pole angle at step end: 93.57735300190892 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 93.57735300190892 Pole angle at step end: 102.48252670098921 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 102.48252670098921 Pole angle at step end: 111.71040542431795 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 111.71040542431795 Pole angle at step end: 121.22195861305079 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 121.22195861305079 Pole angle at step end: 130.97011339327446 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 130.97011339327446 Pole angle at step end: 140.89779070813466 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 140.89779070813466 Pole angle at step end: 150.93624428192368 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 150.93624428192368 Pole angle at step end: 161.00457682030907 Reward in step: 0.0, done: True\n",
      "Pole angle at step start: 161.00457682030907 Pole angle at step end: 171.01141808969234 Reward in step: 0.0, done: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dibya/dropbox_cenvs/rl_course_python3.9/lib/python3.9/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(30):\n",
    "    print(f\"Pole angle at step start: {np.degrees(obs[2])}\", end=\" \")\n",
    "    obs, reward, done, _  = env.step(0)\n",
    "    print(f\"Pole angle at step end: {np.degrees(obs[2])}\", end=\" \")\n",
    "    print(f\"Reward in step: {reward}, done: {done}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1310ae9b-ee1b-4251-b836-ba8519ee1cd6",
   "metadata": {},
   "source": [
    "## Doing multiple episodes\n",
    "\n",
    "- Once `done` is `True`, we should not take any more actions\n",
    "- To collect, call `env.reset()` if you want to restart the simulation from the beginning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa6ff4d-327e-49ef-a8e1-638f67e9e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode number is 1\n",
      "Pole angle at step start: 1.1183983506183337 Pole angle at step end: 1.1099812877349993 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 1.1099812877349993 Pole angle at step end: 1.4439376330601614 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 1.4439376330601614 Pole angle at step end: 2.120212628817913 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 2.120212628817913 Pole angle at step end: 3.1408509750108773 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 3.1408509750108773 Pole angle at step end: 4.509941568170456 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 4.509941568170456 Pole angle at step end: 6.233519072945295 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 6.233519072945295 Pole angle at step end: 8.319416182530764 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 8.319416182530764 Pole angle at step end: 10.77705728546158 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 10.77705728546158 Pole angle at step end: 13.617181963808145 Reward in step: 1.0, done: True\n",
      "Episode number is 2\n",
      "Pole angle at step start: 0.515380400430025 Pole angle at step end: 0.5154796938477244 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 0.5154796938477244 Pole angle at step end: 0.8542054751912109 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 0.8542054751912109 Pole angle at step end: 1.5315570468176798 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 1.5315570468176798 Pole angle at step end: 2.5496370445983056 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 2.5496370445983056 Pole angle at step end: 3.9125971100580776 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 3.9125971100580776 Pole angle at step end: 5.626542358344571 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 5.626542358344571 Pole angle at step end: 7.699388441990249 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 7.699388441990249 Pole angle at step end: 10.140661861706905 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 10.140661861706905 Pole angle at step end: 12.961231805054329 Reward in step: 1.0, done: True\n",
      "Episode number is 3\n",
      "Pole angle at step start: 0.6588394550567872 Pole angle at step end: 0.6595943853173747 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 0.6595943853173747 Pole angle at step end: 0.999871132489477 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 0.999871132489477 Pole angle at step end: 1.6796726995167004 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 1.6796726995167004 Pole angle at step end: 2.7011043286097194 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 2.7011043286097194 Pole angle at step end: 4.068318627288672 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 4.068318627288672 Pole angle at step end: 5.78741898504505 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 5.78741898504505 Pole angle at step end: 7.866315065868991 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 7.866315065868991 Pole angle at step end: 10.314521019689371 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 10.314521019689371 Pole angle at step end: 13.1428847116874 Reward in step: 1.0, done: True\n",
      "Episode number is 4\n",
      "Pole angle at step start: 2.686486534985071 Pole angle at step end: 2.6446455034628626 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 2.6446455034628626 Pole angle at step end: 2.954715294026265 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 2.954715294026265 Pole angle at step end: 3.616439788065407 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 3.616439788065407 Pole angle at step end: 4.631647540017209 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 4.631647540017209 Pole angle at step end: 6.00419592907528 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 6.00419592907528 Pole angle at step end: 7.7398671253939835 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 7.7398671253939835 Pole angle at step end: 9.846210039107733 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 9.846210039107733 Pole angle at step end: 12.332319315178538 Reward in step: 1.0, done: True\n",
      "Episode number is 5\n",
      "Pole angle at step start: -0.18649694955227256 Pole angle at step end: -0.2299740602549958 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: -0.2299740602549958 Pole angle at step end: 0.06075989078835153 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 0.06075989078835153 Pole angle at step end: 0.6854299201252071 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 0.6854299201252071 Pole angle at step end: 1.6458725433049968 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 1.6458725433049968 Pole angle at step end: 2.9459885747323717 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 2.9459885747323717 Pole angle at step end: 4.591657762441804 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 4.591657762441804 Pole angle at step end: 6.590609555024822 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 6.590609555024822 Pole angle at step end: 8.95224106748623 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 8.95224106748623 Pole angle at step end: 11.687370715906582 Reward in step: 1.0, done: False\n",
      "Pole angle at step start: 11.687370715906582 Pole angle at step end: 14.807914528099847 Reward in step: 1.0, done: True\n"
     ]
    }
   ],
   "source": [
    "for ep in range(5):\n",
    "    print(f\"Episode number is {ep+1}\")\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        print(f\"Pole angle at step start: {np.degrees(obs[2])}\", end=\" \")\n",
    "        obs, reward, done, _  = env.step(0)\n",
    "        print(f\"Pole angle at step end: {np.degrees(obs[2])}\", end=\" \")\n",
    "        print(f\"Reward in step: {reward}, done: {done}\")\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c8b67-d873-49c4-b70e-793ee464f5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
