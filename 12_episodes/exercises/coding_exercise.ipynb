{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b697b11-51f4-40cd-a63f-02526cd21ae2",
   "metadata": {},
   "source": [
    "## Calculate expected cumulative reward per episode in `BipedalWalker-v3`\n",
    "\n",
    "The **expected cumulative rewards per episode** is arguably the most important quantity in any RL problem.\n",
    "\n",
    "In this exercise, you will try to compute the expected cumulative rewards per episode in `BipedalWalker-v3` if the robot takes the same action `[1., 1., 1., 0.]` in every step.\n",
    "\n",
    "Ready? Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934cf67-abf1-4680-81d1-e84df92d834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the blanks and execute the cell\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"BipedalWalker-v3\")\n",
    "num_episodes = ____    # Fill in with the number of episodes to execute; higher values will lead to better estimates for the expected value\n",
    "cumulative_rewards = np.array([])\n",
    "for ep in range(num_episodes):\n",
    "    cumulative_reward_this_ep = 0\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        ____, ____, ____, ____ = ____    # Execute the action [1., 1., 1., 0.]; store the reward and whether a terminal state is reached\n",
    "        cumulative_reward_this_ep += ____   # Update the cumulative reward in this episode with the latest stepwise reward \n",
    "        ____:    # Write the condition for ending the episode when a terminal state is reached\n",
    "            break\n",
    "    cumulative_rewards = np.append(cumulative_rewards, cumulative_reward_this_ep)\n",
    "expected_cumulative_rewards = ____    # Calculate the average cumulative reward per episode\n",
    "print(f\"The exepected cumulative reward is {expected_cumulative_rewards}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f12216-4607-40bb-8664-5425bdd0cf0d",
   "metadata": {},
   "source": [
    "You should get an output close to -110. \n",
    "\n",
    "Did you get the desired output? If so, well done!\n",
    "\n",
    "By the way, if you are feeling curious about how the terminal states in `BipedalWallker-v3` are defined, you can find them in the `BipedalWalker` class' docstring in the [source code](https://github.com/openai/gym/blob/master/gym/envs/box2d/bipedal_walker.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
