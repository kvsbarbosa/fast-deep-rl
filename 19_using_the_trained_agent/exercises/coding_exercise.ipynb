{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f49e11-ceb5-432f-aa37-51f959315f77",
   "metadata": {},
   "source": [
    "# Create a video of the walking robot\n",
    "\n",
    "By now, the robot should have reached an evaluation performance > 250 cumulative rewards per episode. \n",
    "\n",
    "![250](250.png)\n",
    "\n",
    "That means the robot is able to walk.\n",
    "\n",
    "In this exercise, we will create a video of the walking robot.\n",
    "\n",
    "In the last exercise, you created checkpoints (saved agents) in the relative path `bipedal_walker_v3`. Find the last checkpoint file and use it to restore the agent in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38675e-b02e-4f45-83fa-922e14248e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the PPO agent from the last checkpoint file and save it in a variable called agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e2bf2-a9d2-48df-8c80-a0f957213564",
   "metadata": {},
   "source": [
    "Once we have a restored agent, we simply need to use `gym`'s video recorder to record a video.\n",
    "\n",
    "- You need to import gym's video recorder class and wrap the `BipedalWalker-v3` environment (this makes the environment video capable)\n",
    "- Make sure you store the video in a folder with the relative path `bipedal_walker_video`\n",
    "- Use the restored agent to take actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5af67-0947-4425-ad5e-11b39a2b9e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "# Import the video recorder class below\n",
    "____\n",
    "\n",
    "\n",
    "# Crete a video capable `BipedalWalker-v3` environment\n",
    "env = ____    # The videos should be saved to the relative path bipedal_walker_video\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action = ____    # Compute the action according to the restored agent's policy\n",
    "    obs, r, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04dc847-667e-4107-8366-ea3e8f04eec2",
   "metadata": {},
   "source": [
    "Now just go to the `bipedal_walker_video` folder and play the mp4 file. \n",
    "\n",
    "Amazing, isn't it? You just taught this robot how to walk from scratch. That's no mean feat. Congratulations!\n",
    "\n",
    "You can use the same procedure to solve other environments in `gym`. If you are feeling adventurous, give `CarRacing-v0` and `LunarLander-v2` a try, for example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
